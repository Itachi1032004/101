program 1 SOLVING XOR PROBLEM USING MULTILAYER PERCEPTRON.
 import numpy as np
from keras.models import Sequential
from keras.layers import Dense
X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_train = np.array([[0], [1], [1], [0]])
model = Sequential()
model.add(Dense(1, input_dim=2, activation='relu')) # Hidden layer with 8 neurons model.add(Dense(1, activation='sigmoid')) # Output layer with 1 neuron
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=3, batch_size=4)
loss, accuracy = model.evaluate(X_train, y_train)
print(f"Loss: {loss}, Accuracy: {accuracy}")
X_test = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
predictions = model.predict(X_test)
print(predictions)
for i in range(len(X_test)):
    print(f"Input: {X_test[i]}, Predicted Output: {predictions[i]}")


Program 2 IMPLEMENTATION OF IMAGE CLASSIFICATION USING CNN.
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
# Load the LFW dataset
lfw_dataset = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
# Extract the images and labels
images = lfw_dataset.images
labels = lfw_dataset.target
target_names = lfw_dataset.target_names
# Preprocess the data
images = images.astype('float32') / 255
labels = to_categorical(labels)
# Split the data into training and testing sets
train_images, test_images, train_labels, test_labels = train_test_split(images, labels,  test_size=0.2)
# Create the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(50, 37, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(len(target_names), activation='softmax'))
# Compile and train the model
model.compile(optimizer='rmsprop',
 loss='categorical_crossentropy',
 metrics=['accuracy'])
model.fit(train_images, train_labels, batch_size=32, epochs=3)
# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)
# Select a sample image for prediction
sample_index = 0
sample_image = test_images[sample_index]
sample_label = np.argmax(test_labels[sample_index])
sample_name = target_names[sample_label]
# Make a prediction on the sample image
sample_image = np.expand_dims(sample_image, axis=0)
prediction = model.predict(sample_image)
predicted_label = np.argmax(prediction)
predicted_name = target_names[predicted_label]
# Display the sample image and the predicted and true labels
plt.imshow(sample_image[0], cmap='copper')
plt.title(f'Predicted: {predicted_name}\nTrue: {sample_name}')
plt.axis('off')
plt.show()

program 3 BUILDING A DEEP LEARNING MODEL.
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Generate synthetic data for binary classification
np.random.seed(0)
X = np.random.randn(1000, 10)  # 1000 samples with 10 features
y = np.random.randint(2, size=1000)  # Binary labels (0 or 1)

# Split data into training and testing sets
X_train, X_test = X[:800], X[800:]
y_train, y_test = y[:800], y[800:]

# Step 1: Define the architecture of the neural network
input_dim = X_train.shape[1]  # Number of features
hidden_layers = 2
neurons_per_layer = 64
activation_function = 'relu'
output_dim = 1  # Binary classification

# Step 2: Build the model
model = Sequential()
model.add(Dense(neurons_per_layer, input_dim=input_dim, activation=activation_function))
for _ in range(hidden_layers - 1):
    model.add(Dense(neurons_per_layer, activation=activation_function))
model.add(Dense(output_dim, activation='sigmoid'))  # Output layer

# Step 3: Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Step 4: Train the model
epochs = 3
batch_size = 32
model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)

# Step 5: Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

program 4 IMPLEMENT THE ANALYSIS OF X-RAY IMAGE USING AUTOENCODERS.
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
x_ray_image = np.random.rand(256, 256)
noisy_x_ray = x_ray_image + np.random.normal(0, 0.1, x_ray_image.shape)
x_ray_image = x_ray_image / 255.0
noisy_x_ray = noisy_x_ray / 255.0
input_layer = Input(shape=(256, 256))
encoded = Dense(128, activation='relu')(input_layer)
decoded = Dense(256, activation='sigmoid')(encoded)
autoencoder = Model(input_layer, decoded)
autoencoder.compile(optimizer='adam', loss='mean_squared_error')
autoencoder.fit(noisy_x_ray, x_ray_image, epochs=3)
denoised_x_ray = autoencoder.predict(np.expand_dims(noisy_x_ray, axis=0))
plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.imshow(x_ray_image, cmap='gray')
plt.title("Original X-ray")
plt.subplot(1, 3, 2)
plt.imshow(noisy_x_ray, cmap='gray')
plt.title("Noisy X-ray")
plt.subplot(1, 3, 3)
plt.imshow(denoised_x_ray[0], cmap='gray')
plt.title("Denoised X-ray")
plt.tight_layout()
plt.show()

program 5 IMPLEMENT SPEECH RECOGNITION USING NLP.
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense
from tensorflow.keras.models import Model
import numpy as np
sample_audio_features = np.random.rand(100,100, 20)
input_layer = Input(shape=(100, 20))
embedding = Embedding(input_dim=10000, output_dim=128)(input_layer)
embedding_reshaped=tf.keras.layers.Reshape((-1,128))(embedding)
lstm = LSTM(128)(embedding_reshaped)
output_layer = Dense(10, activation='softmax')(lstm)
speech_recognition_model = Model(inputs=input_layer, outputs=output_layer)
speech_recognition_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
sample_labels = np.random.randint(10, size=(100, 10))
speech_recognition_model.fit(sample_audio_features, sample_labels, epochs=10, batch_size=32)
sample_input_audio = np.random.rand(1, 100, 20)
predicted_probs = speech_recognition_model.predict(sample_input_audio)
predicted_word_index = np.argmax(predicted_probs)
print("Predicted Word Index:", predicted_word_index)


program 6 DEVELOP A CODE TO DESIGN OBJECT DETECTION AND 

CLASSIFICATION FOR TRAFFIC ANALYSIS USING CNN
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.models import Sequential
sample_images = np.random.rand(100, 64, 64, 3)
sample_labels = np.random.randint(2, size=100)
model = Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),MaxPooling2D((2, 2)),Conv2D(64, (3, 3), activation='relu'),MaxPooling2D((2, 2)),Conv2D(128, (3, 3), activation='relu'),MaxPooling2D((2, 2)),Flatten(),Dense(128, activation='relu'),Dense(1, activation='sigmoid')])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(sample_images, sample_labels, epochs=10, batch_size=32)
sample_traffic_image = np.random.rand(1, 64, 64, 3)
prediction = model.predict(sample_traffic_image)
print("Predicted Probability:", prediction)

program 7 IMPLEMENT ONLINE FRAUD DETECTION OF SHARE MARKET DATA 

USING ANY ONE OF THE DATA ANALYTICS TOOLS.
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
data = pd.read_csv('C://Users//STUDENT//Downloads//archive (2)//AMZN.csv')
features = ['Adj Close', 'Volume']
train_data, test_data = train_test_split(data[features], test_size=0.2, random_state=42)
model = IsolationForest(contamination=0.05)
model.fit(train_data)
predictions = model.predict(test_data)
num_anomalies = len(predictions[predictions == -1])
print("Number of Anomalies Detected:", num_anomalies)

program 8 IMPLEMENTATION OF RNN.
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Define your text corpus for training
text = "The quick brown fox jumped over the lazy dog"

# Create a vocabulary (set of unique characters in the text)
vocab = sorted(set(text))

# Create a mapping from characters to integers and vice versa
char_to_index = {char: index for index, char in enumerate(vocab)}
index_to_char = {index: char for index, char in enumerate(vocab)}

# Prepare training data
max_sequence_length = 10  # Adjust as needed
step = 1
sequences = []
next_chars = []
for i in range(0, len(text) - max_sequence_length, step):
    input_sequence = text[i: i + max_sequence_length]
    target_char = text[i + max_sequence_length]
    sequences.append([char_to_index[char] for char in input_sequence])
    next_chars.append(char_to_index[target_char])

# Prepare input data as tensors
x = np.zeros((len(sequences), max_sequence_length, len(vocab)), dtype=bool)
y = np.zeros((len(sequences), len(vocab)), dtype=bool)
for i, sequence in enumerate(sequences):
    for t, char_index in enumerate(sequence):
        x[i, t, char_index] = 1
    y[i, next_chars[i]] = 1

# Build the RNN model
model = Sequential()
model.add(LSTM(128, input_shape=(max_sequence_length, len(vocab))))
model.add(Dense(len(vocab), activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam')

# Train the model
model.fit(x, y, batch_size=128, epochs=5)

# Generate text using the trained model
def generate_text(seed_text, num_chars_to_generate=10):
    generated_text = seed_text
    for _ in range(num_chars_to_generate):
        input_sequence = generated_text[-max_sequence_length:]
        x_pred = np.zeros((1, max_sequence_length, len(vocab)), dtype=bool)
        for t, char in enumerate(input_sequence):
            x_pred[0, t, char_to_index[char]] = 1
        predicted_char_index = np.argmax(model.predict(x_pred, verbose=0))
        predicted_char = index_to_char[predicted_char_index]
        generated_text += predicted_char
    return generated_text

seed_text = "The quick brown fox jumped over the lazy dog"

# Define the number of times to repeat the sentence
num_chars_to_generate=10
# Generate the output
generated_text = ""
for i in range(num_chars_to_generate):
    generated_text += seed_text + ", and "
generated_text = generated_text[:-6]  # Remove the last ", and "

# Print the output
print(generated_text)

program 9 IMPLEMENT IMAGE AUGMENTATION USING DEEP RBM
import numpy as np
from sklearn.neural_network import BernoulliRBM
import matplotlib.pyplot as plt
# Generate a sample dataset of images (you would use actual images in practice)
num_samples = 100
image_size = 8 * 8
original_images = np.random.randint(0, 2, size=(num_samples, image_size))
# Define a deep RBM with two hidden layers
rbm = BernoulliRBM(n_components=64, n_iter=10, batch_size=10)
rbm2 = BernoulliRBM(n_components=64, n_iter=10, batch_size=10)
# Fit the RBM layers
rbm.fit(original_images)
hidden_features = rbm.transform(original_images)
rbm2.fit(hidden_features)
augmented_features = rbm2.transform(hidden_features)
# Reconstruct augmented images
reconstructed_hidden_features = rbm.transform(augmented_features)
reconstructed_hidden_features_transformed = rbm.transform(reconstructed_hidden_features)
reconstructed_images = rbm.transform(reconstructed_hidden_features_transformed)
# Plot original and augmented images
plt.figure(figsize=(10, 4))
for i in range(5):
    plt.subplot(2, 5, i + 1)
    plt.imshow(original_images[i].reshape(8, 8), cmap='gray')
    plt.title("Original")
    plt.subplot(2, 5, i + 6)
    plt.imshow(reconstructed_images[i].reshape(8, 8), cmap='gray')
    plt.title("Augmented")
plt.tight_layout()
plt.show()

program 10 IMPLEMENT SENTIMENT ANALYSIS USING LSTM.
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
texts = [
 "I love this product!",
 "This is terrible.",
 "The movie was amazing.",
 "I'm not sure how I feel about it."
]
labels = np.array([1, 0, 1, 0])
tokenizer = Tokenizer(num_words=1000, oov_token="<OOV>")
tokenizer.fit_on_texts(texts)
word_index = tokenizer.word_index
sequences = tokenizer.texts_to_sequences(texts)
padded_sequences = pad_sequences(sequences, maxlen=10, padding='post',
truncating='post')
model = tf.keras.Sequential([
 tf.keras.layers.Embedding(input_dim=len(word_index) + 1, output_dim=16,
input_length=10),
 tf.keras.layers.LSTM(16),
 tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(padded_sequences, labels, epochs=3, verbose=1)
sample_test_text = ["This is a great product!"]
sample_test_sequence = tokenizer.texts_to_sequences(sample_test_text)
sample_padded_sequence = pad_sequences(sample_test_sequence, maxlen=10,
padding='post', truncating='post')
prediction = model.predict(sample_padded_sequence)
print("Predicted Sentiment:", "Positive" if prediction > 0.5 else "Negative")

program 11 IMPLEMENT VARIATIONAL AUTO ENCODERS
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.datasets import mnist
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
# Flatten the images for the autoencoder
x_train_flat = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test_flat = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
input_img = Input(shape=(784,))
encoded = Dense(128, activation='relu')(input_img)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dense(32, activation='relu')(encoded)
decoded = Dense(64, activation='relu')(encoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dense(784, activation='sigmoid')(decoded)
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
autoencoder.fit(x_train_flat, x_train_flat, epochs=5, batch_size=256, shuffle=True,
validation_data=(x_test_flat, x_test_flat))
encoded_imgs = autoencoder.predict(x_test_flat)
encoded_imgs = encoded_imgs.reshape((len(x_test), 28, 28))
n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i])
    plt.title("Original")
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(encoded_imgs[i])
    plt.title("Reconstructed")000
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
